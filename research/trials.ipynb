{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nipun\\\\Desktop\\\\Medchatbot'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 39711\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipun\\AppData\\Local\\Temp\\ipykernel_33780\\1196424635.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY=os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'medbot' is ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Your Pinecone API key\n",
    "PINECONE_API_KEY = \"pcsk_6hfbZM_PyDhaPVXZs1H5ddoLnsEWx7iNai3SZR8Mfbgsf59yEKteEmXsiatUEu5q2RPML2\"  # Replace with your actual API key\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"medbot\"\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Adjust based on your embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Index '{index_name}' is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# Ensure PyTorch uses GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the embedding model and move it to GPU\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "\n",
    "# Custom embedding class for LangChain compatibility\n",
    "class CustomEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        with torch.no_grad():\n",
    "            return embedding_model.encode(texts, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# Instantiate the custom embedding class\n",
    "embedding_instance = CustomEmbeddings()\n",
    "\n",
    "# Batch processing for Pinecone upsert\n",
    "batch_size = 1000  # Adjust as needed\n",
    "for i in range(0, len(text_chunks), batch_size):\n",
    "    docsearch = PineconeVectorStore.from_documents(\n",
    "        documents=text_chunks[i:i+batch_size],\n",
    "        index_name=index_name,\n",
    "        embedding=embedding_instance  # Use the instance, not a function\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x227a7be1490>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Cancer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain_pinecone in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.34)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.10.6)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (2024.7.4)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (2.2.2)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: aiohttp<3.11,>=3.10 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_pinecone) (3.10.11)\n",
      "Requirement already satisfied: langchain-tests<0.4.0,>=0.3.7 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_pinecone) (0.3.11)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_pinecone) (1.26.4)\n",
      "Requirement already satisfied: pinecone<6.0.0,>=5.4.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_pinecone) (5.4.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: pytest<9,>=7 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (8.3.4)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (0.25.3)\n",
      "Requirement already satisfied: syrupy<5,>=4 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (4.8.1)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
      "INFO: pip is looking at multiple versions of pinecone to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pinecone<6.0.0,>=5.4.0 (from langchain_pinecone)\n",
      "  Using cached pinecone-5.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached pinecone-5.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting langchain_pinecone\n",
      "  Using cached langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached langchain_pinecone-0.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohttp<3.10,>=3.9.5 (from langchain_pinecone)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "INFO: pip is still looking at multiple versions of pinecone to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_pinecone\n",
      "  Using cached langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain_pinecone) (0.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nipun\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "Using cached langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: pinecone-plugin-inference, uvicorn, starlette, aiohttp, fastapi, langchain_pinecone\n",
      "  Attempting uninstall: pinecone-plugin-inference\n",
      "    Found existing installation: pinecone-plugin-inference 3.1.0\n",
      "    Uninstalling pinecone-plugin-inference-3.1.0:\n",
      "      Successfully uninstalled pinecone-plugin-inference-3.1.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.10.11\n",
      "    Uninstalling aiohttp-3.10.11:\n",
      "      Successfully uninstalled aiohttp-3.10.11\n",
      "  Attempting uninstall: langchain_pinecone\n",
      "    Found existing installation: langchain-pinecone 0.2.2\n",
      "    Uninstalling langchain-pinecone-0.2.2:\n",
      "      Successfully uninstalled langchain-pinecone-0.2.2\n",
      "Successfully installed aiohttp-3.9.5 fastapi-0.115.8 langchain_pinecone-0.2.0 pinecone-plugin-inference-1.1.0 starlette-0.45.3 uvicorn-0.34.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~iohttp'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set API key directly\n",
    "api_key = \"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\"\n",
    "\n",
    "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\", temperature=0.4, max_tokens=500, api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question as thoroughly as possible. Provide a detailed \"\n",
    "    \"and well-structured response. Avoid giving vague or overly \"\n",
    "    \"short answers. If you don't know the answer, say that you \"\n",
    "    \"don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the question-answering chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Assume `retriever` is already defined elsewhere\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systemic Lupus Erythematosus (SLE) is a systemic autoimmune disease, which means that it can affect multiple organs and tissues in the body. The hallmark of SLE is the presence of autoimmune manifestations that are likely to be etiologic in the organ pathology.\n",
      "\n",
      "One of the key features of SLE is the production of a vast array of autoantibodies, which are antibodies that target the body's own cells and tissues. These autoantibodies are produced as a result of a generalized hyperreactivity of the humoral immune system, which is the part of the immune system that produces antibodies.\n",
      "\n",
      "In addition to generalized B cell hyperresponsiveness and polyclonal hypergammaglobulinemia, which is an increase in the level of certain types of antibodies in the blood, people with SLE also often have increased titers of antibodies to commonly encountered viral antigens.\n",
      "\n",
      "There are several specific autoantibodies that are commonly found in people with SLE. These include antibodies to double-stranded DNA (dsDNA) and to Sm, which are relatively specific for SLE. Other autoantibodies that may be found in people with SLE are listed in Table 311-1, although the specific contents of this table are not provided in the context.\n",
      "\n",
      "It is important to note that a positive test for ANAs, or antinuclear antibodies, which are a type of autoantibody, supports the diagnosis of SLE but is not specific to the disease. This means that a negative ANA test makes the diagnosis of SLE unlikely, but it does not rule it out completely. Similarly, other autoimmune diseases, viral infections, chronic inflammatory processes, and several drugs can also induce ANAs, so a positive ANA test does not necessarily mean that a person has SLE.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the RAG pipeline\n",
    "response = rag_chain.invoke({\"input\": \"what are the auto antibodies found in SLE?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
